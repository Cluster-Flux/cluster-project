{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.acquire\n",
    "import src.prepare\n",
    "import src.preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement | Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I'll go over how and where we're getting the data from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where the Data is Coming From"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data was provided by the Zillow team as part of a Kaggle competition. More information about the competition can be found here: https://www.kaggle.com/c/zillow-prize-1.\n",
    "\n",
    "The data from the competition was saved to a mySQL database, which we'll pull into a pandas DataFrame to explore and model off of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the Data is Being Filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll explain what we used to filter information through our SQL query:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fill this in!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV previously generated at `data/raw/zillow_unprocessed.csv`. Reading in that csv as a DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Reading in the data from the acquire.py into a dataframe\n",
    "df = src.acquire.get_zillow_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What metric are we using to drop features? \n",
    "> *If a specific feature is missing more than 50 percent of it's values, we'll drop it*\n",
    "\n",
    "- What metric are we using to drop rows? \n",
    "> *If a row is missing more than 75 percent of it's values, we'll drop it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Number of rows dropped:    156\n",
      "    Number of columns dropped: 34\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Dropping features and rows with too many missing values\n",
    "df = src.prepare.handle_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While this helped us get rid of a decent number of unusable observations (rows), this process helps us greatly reduce the number of insignificant features in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Nulls with Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For each feature listed below, we'll be filling the null values with the median of the feature. \n",
    "\n",
    "> This in particular will help for these features at it will reduce the effect of outliers within the data.\n",
    "\n",
    "```\n",
    "Features\n",
    "- taxvaluedollarcnt:            $358,880\n",
    "- taxamount:                    $4448.72\n",
    "- fullbathcnt:                  2 bathrooms\n",
    "- lotsizesquarefeet:            7,205 sqft\n",
    "- calculatedfinishedsquarefeet: 1,542 sqft\n",
    "- structuretaxvaluedollarcnt:   $136,389\n",
    "- finishedsquarefeet12          1,523 sqft\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = src.prepare.fill_nulls_with_median(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Nulls with Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For each feature listed below, we'll be filling the null values with the mode of the feature. \n",
    "\n",
    "```\n",
    "Features\n",
    "- regionidzip:           97319\n",
    "- regionidcity:          12447\n",
    "- yearbuilt:             1955\n",
    "- landtaxvaluedollarcnt: $21,299\n",
    "- lotsizesquarefeet:     6,000 sqft   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = src.prepare.fill_nulls_with_mode(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we've created a threshold to drop columns based on missing values, there's still some columns we should drop to clean up the dataframe:\n",
    "\n",
    "```\n",
    "Columns to Drop\n",
    "- buildingqualitytypeid  -|\n",
    "- heatingorsystemtypeid   | --> These features were used to merge in mySQL\n",
    "- propertylandusetypeid  -|\n",
    "\n",
    "- propertycountylandusecode: We've already filtered for single unit residents\n",
    "- propertyzoningdesc:  Irrelevant data\n",
    "- censustractandblock: Too many missing values\n",
    "- Unnamed: 0: Remnant of reading from a csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "df = src.prepare.drop_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fips to county name, use https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt\n",
    "df.fips = df.fips.replace({6037.0:'Los_Angeles_County', 6059.0:'Orange_County', 6111.0:'Ventura_County'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validate = src.preprocessing.split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the selected features to 'object' types to preserve them\n",
    "for df in [train, test, validate]:\n",
    "    src.prepare.numeric_to_object(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "for df in [train, test, validate]:\n",
    "    src.preprocessing.scale_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make your titles and labels meaningful, make your number formats friendly to the end user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Correlation By County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's chart out a subset of columns for now, so the charts run in a decent amount of time\n",
    "df = train[[\"bathroomcnt\", \"bedroomcnt\", \"lotsizesquarefeet\", \"yearbuilt\", \"calculatedfinishedsquarefeet\", \"taxamount\", \"taxvaluedollarcnt\", \"logerror\", \"fips\", \"longitude\", \"latitude\", \"regionidzip\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap='RdYlBu', annot=True, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation between number of bedrooms and number of bathrooms makes sense, as well as a correlation between longitude and latitude. \n",
    "> We can make a feature to combine bathroom and bedroom count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "sns.scatterplot(x='longitude', y='latitude', hue='fips', data=df)\n",
    "plt.xticks(ticks=[])\n",
    "plt.yticks(ticks=[])\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
